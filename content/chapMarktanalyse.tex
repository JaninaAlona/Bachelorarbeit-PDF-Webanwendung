\chapter{Stand der Technik}
Die Popularität von PDF-Dateien ist seit 2008 rasant angestiegen in der globalen Informationsübertragung. Täglich werden weltweit 2,5 Milliarden PDF Dokumente erzeugt. Seine Beliebtheit verdankt PDF vor allem an der plattformübergreifenden Kompatibilität (Desktop-Computer, Tablets und Smartphones), denn PDF Dokumente ist auf mehr als 1,5 Milliarden Geräten ohne zusätzliche Software lesbar. Über 80\% der geschäftlichen Dokumente werden als PDF Datei weitergegeben. \cite{formilo} 90 \% der Büroangestellten wollen auf das PDF Dateiformat nicht mehr verzichten. Drei Viertel aller archivierten Dokumente sind PDF Dokumente (2023).
Bis 2025 werden über 3 Millarden Dollar jährlich für PDF Editoren ausgegeben werden (2023) \cite{kofax}. Im Jahr 2015 gab es 1,6 Milliarde PDF-Dokumente im Web und im Jahr 2019 wurden PDF-Dateien bei ca. 99 \% Firmen und Regierungsinstitutionen weltweit verwendet \cite{ccc-break-pdf}. 

\section{Generative AI}
Generative artificial intelligence (AI) Anwendungen können das Arbeiten mit Text, Bildern, Code und Dokumenten wie PDF erleichtern. Solche Anwendungen sind seit einigen Jahren wertvolle Tools in vielen Businessumgebungen und -workflows. Sie kommen in Tools für Teamkollaboration, wie Zoom, \gls{ccaas} Plattformen und Produktivitätsapps vor. Einer der prominentesten Beispiele sind Microsoft Copilot und Google Duet AI. Sie bauen auf ein \gls{llm} auf und bedienen sich Algorithmen zur Gesprächsführung. Mittels \gls{nlp} und hochmodernen Algorithmen können generative AI Anwendungen mit Menschen interagieren. Durch eine Benutzeraufforderung (prompt) kann der Benutzer Fragen oder Befehle an das Tool übermitteln und erhält menschenähnliche Antworten in wenigen Sekunden \cite{copilot-duet}. Ein \gls{llm} ist ein deep learning Algorithmus, der \gls{nlp} Aufgaben bewältigen kann. Dabei werden transformer models verwendet und das \gls{llm} wird durch große Datensätze trainiert, wodurch sie Text und andere Inhalte erkennen, übersetzen, vorhersagen oder generieren können. Im Prinzip sind \gls{llm}s neural networks, die ebenso trainiert und fein abgestimmt werden müssen. Sie haben eine große Anzahl an Parameter, die vom Lernen und Trainieren als Wissensdatenbank herrühren. \gls{llm}s bestehen aus multiplen network layers: Recurrent layers, feedforward layers, embedding layers und attention layers. Die embedding layer erstellt embeddings vom Benutzerinput und arbeitet die semantische und syntaktische Bedeutung zum Kontextverständnis heraus. Des Weiteren besteht die feedforward layer als \gls{ffn} aus multiplen völlig verbundenen Schichten, die die input embeddings transformieren. Dabei kann das model eine höhere Abstraktionsebene zum Verständnis der Benutzertextes gewinnen. In der recurrent layer wird der input Text als Sequenz interpretiert und die Beziehung zwischen Wörtern wird erfasst. Der attention Mechanismus ermöglicht dem model sich auf einzelne Teile des inputs zu fokussieren und das akkurateste Output wird geliefert. Es gibt 3 Hauptkategorien von \gls{llm}s: Generic or raw language models, instruciton-tuned language models und dialog-tuned language models. Generic or raw language models werden zur Informationsgewinnung eingesetzt, da sie das nächste Wort basierend auf der Sprache der Trainingsdaten vorhersagen können. Instruction-tuned language models sind trainiert, um Antworten auf Input-Anweisungen zu geben. Durch den Output können Stimmungen analysiert werden bzw. diese \gls{llm}-Art kann Code oder Text generieren. Dialog-tuned langauge models sind als chatbot oder conversational AI geschult einen Dialog zu führen, indem die nächste Antwort prognostiziert wird. Ein transformer model ist die gängigste Architektur eines \gsl{llm}s und besteht aus einem Encoder und Decoder. Input-Daten werden durch Zuweisung von tokens verarbeitet und gleichzeitig werden mathematische Gleichungen ausgeführt, um die Beziehung zwischen den tokens zu erfassen. Dadurch kann der Computer Muster, die ein Mensch sehen würde, erkennen. Transformers arbeiten mit dem self-attention Mechanismus, was dem transformer ermöglicht, schneller zu arbeiten, als long short-term memory models. Self-attention ermöglicht dem transformer model verschiedene Teile oder den Gesamtkontext einer Sequenz für Vorhersagen in Betracht zu ziehen \cite{nlp-def}. \\

Copilot ist u.a. in die Bing Suchmaschine, Microsoft Office, Microsoft Teams und Windows 11 integriert. Seine Funktionalität variiert, je nachdem wo es verwendet wird. Bei Word kann Copilot behilflich sein, um Dokumente zu skizzieren, Quellen für Informationen in einem Dokument zu suchen, Wortvorschläge zu machen und Schreibhilfe zu leisten. Benutzer können Informationen aus anderen Microsoft Dokumenten, wie z.B. PowerPoint, ziehen, um ihr aktuelles Dokument zu füllen oder sein aktuelles Dokument an die Formatierung von einem anderen Dokument anpassen. In Bezug auf Excel ist Copilot ein Analysetool, um Daten zu visuelle Repräsentationen zu transformieren oder bei automatisierten Prozessen. Der bot kann sogar Trends von Schlüsseldaten, und Fehler korrigieren, Zellen automatisch vervollständigen und Berechnungen erklären. Bei PowerPoint kann Copilot Präsentationen basierend auf Informationen und Dokumente des Microsoft Ökosystems erstellen. Präsentationsfolien können auf Grundlage von spezifischen Instruktionen, wie passend zum eigenen Stil oder der Stimme, gestaltet werden. Google Duet AI ist ein Bestandteil des Google Workspace Apps und Entwicklertools. Der Service unterstützt mehr als 20 Programmiersprachen bei der Code Assistenz. Benutzer können AppSheets verwenden, um intelligente Businessanwendungen und Workflows zu erstellen. Google bietet außerdem die Vertex Platform für Entwicklung an. Bei Google Docs gibt es ein Duet Feature Help Me Write zur Erstellung von Dokumenten. Basis ist ein prompt, der beschreibt, über was der Benutzer gerne schreiben möchte und das AI System arbeitet ein passendes Dokument heraus. Das Feature Smart Chips wird für variable Informationen verwendet. Hierbei kann der Benutzer bestimmte Inhaltspassagen mit Bedingungen bezogen auf einen Ort oder eines bestimmten Businesses versehen. Help Me Write ist für viele Sprachen verfügbar und kann eine Reihe an unterschiedlichen Typen von Dokumenten von Blogs zu Jobbeschreibungen kreieren. Im Falle von Google Sheets bietet Duet eine Datenanalyse an. Durch \gls{nlp} Technologie assistiert Duet Benutzern bei der Dokumentennavigation und Erstellung von benutzerdefinierten Templates, um Daten zu organisieren. Mächtige Tools für Datenklassifizierung unterstützen den Benutzer Datenkontexte zu verstehen. Zusätzlich kann Duet Fehler finden und berichtigen, Zellen automatisch füllen und Vorschläge für eine Analyse machen. Bei Google Slides spielt Duet ebenfalls eine Rolle beim Erstellen und Optimieren von Präsentationen. Bilder können mittels des Help Me Visualize Werkzeugs generiert werden und Bilddesigns können mit verschiedenen Styles angepasst werden. Duet assistiert ebenfalls beim Notizen Schreiben für Präsentationen und dass das Layout der Präsentation konsistent aussieht. Sowohl Copilot als auch Duet können beim E-Mail Schreiben und Video-Meetings behilflich sein. Vor allem Duet bietet Assistenz beim Programmieren. Sowohl Copilot als auch Duet sind noch in der preview Phase, d.h. sie werden in Zukunft kostenpflichtig sein \cite{copilot-duet}. \\

\gls{ie} ist eine Unterkategorie von \gls{nlp} und ist relevant für die Identifizierung von relevanten Informationen in Text und die Extrahierung dieser Informationen zu spezifischen Output-Formaten. Bei der \gls{re} werden relevante Einheiten im Text in Beziehung zueinander gesetzt. Normalerweise wird bei der \gls{ocr}-Technologie zunächst das Bild in Graustufen konvertiert und eine Texterkennungsphase wird eingeleitet, in der Stellen identifiziert werden, wo sich Informationen befinden. Auf diese Stellen werden Textboxen generiert. Danach liest die \gls{ocr}-Engine wie Tesseract den Inhalt jeder Box im Bild und konvertiert ihn zu Text. Zuletzt wird ein Algorithmus eingesetzt, der eine post-\gls{ocr} pipeline oder language model sein kann, um extrahierte Informationen zu klassifizieren. Beispiele für solche Anwendungen sind Amazon Textract oder Microsoft Azure AI Document Intelligence. Eine bessere Alternative für \gls{ocr}-Anwendungen stellt die \gls{ocr}-freie Lösung Donut dar. Donut ist ein Visual Document Understanding model, was ein Bild als input aktzeptiert und textbasierte Aufgaben lösen kann, wie Informationsgewinnung und Beantwortung von visuellen Fragen. Mit Fokus auf deep learning img2seq models verwendet Donut als Ersatz zur \gls{ocr}-Technologie einen visuellen Encoder (Swin-B transformer) und einen Textdecoder (BART). Swin-B ist eine transformer Architektur, die speziell auf image processing zugeschnitten ist. Bilder werden vom transformer in Segmente unterteilt und hierarchisch verarbeitet, um lokale und globale kontextuelle Informationen zu erfassen. Die Bildsegmente werden mittels eines shifted window-based multi-head self-attention Moduls analysiert, um die Beziehungen zwischen benachbarten Segmenten zu erfassen. Danach ermöglicht eine two-layer \gls{mlp} dem model das Schema in jedem Segment zu lernen, damit es ein besseres Verständnis der Bildinhalts entwickeln kann. Zum Schluss durchlaufen die tokens des Segments die Schichten, die die Segmente wieder zusammenfügen, was dem model ermöglicht, Informationen zu kumulieren und ein verständlichere Repräsentation des Bildes zu liefern. Der output dieses Prozesses wird Decoder, einem multilingual BART model, übergeben \cite{transformers-ocr}. \\

Amazon Textract ist ein ML-Service, der automatisch Text, Handschrift, Layoutelemente und Daten von gescannten Dokumenten, Bildern oder PDF-Dateien ohne manuelle Konfiguration extrahieren kann. Bei Textract handelt es sich um einen \gls{aws} Cloud-Dienst. Im Gegensatz zu traditionellen \gls{ocr}-Anwendungen kann Textract außerdem strukturierte Informationen aus Tabellen oder Formularen erfassen. Nebst Zeichenerkennung werden auch Formatierungen, sowie die Struktur des Text herausgearbeitet. Der Service kann per Konsole, Command Line Interface (CLI) oder Application Programming Interface (API) verwendet werden. Mittels der Detect Document Text API wird eine \gls{ocr}-Schnittstelle bereitgestellt, um handschriftliche oder gedruckte Texte aus Dokumenten zu entnehmen. Zusätzlich hat die Analyze Document API das Aufgabenfeld, strukturierte Daten einzulesen und Beziehungen bzw. Schlüsselwertpaare aus Tabellen- oder Formularfelder zu erstellen. Extrahierte Informationen sind mit einem Confidence-Score versehen, um dem Benutzer mitzuteilen, wie exakt und verlässlich die Daten sind. Handschriftlicher und gedruckter Text kann mit hoher Genauigkeit und Zuverlässigkeit erkannt werden. Die Extraktion der Daten geschieht sehr performant in kurzer Zeit. Das Pricing des Produkts ist nutzungsabhängig \cite{textract}. \\

Perplexity AI ist ein Werkzeug für \gls{nlp} mit Dokumenten. Ingesamt kann man bei Perplexity zwischen den generativen AI assistants Perplexity, \gls{gpt4} oder Claude 2 bei Dateiuploads wählen. Eine PDF-Datei als Dateiformat, plaintext oder Code kann hochgeladen werden und Perplexity verwendet dessen Dateiinhalte, um Antworten auf Fragen zum PDF inklusive Zitate mit Quellenangaben zu formulieren. Bei kurzen Dateien wird das gesamte Dokument beim language model analysiert. Umfangreiche PDFs können manuell in Themenbereiche unterteilt werden und als input für \gls{gpt4} für Kreatives Schreiben verwendet werden. Wissenschaftliche Artikel können verglichen, ihre Unterschiede herausgearbeitet, themenverwandte Dokumente durch eine query gefunden, Daten analysiert, Überblicke von verschiedenen Quellen generiert, Daten visualisiert, Grafiken von Quellen erstellt und Text in eine andere Sprache übersetzt werden. Bei der kostenlosen Version ist der Benutzer auf eine bestimmte Anzahl an Anfragen begrenzt \cite{hackernoon-claude}. Claude 2 model von Anthropic ist verfügbar in Perplexity beim Dateiupload. Der AI assistant kann PDFs parsen und die Dokumentstruktur mittels Machine Learning (ML) Techniken erfassen. Es hat eine eingebaute PDF analyser Komponente. Die maximale Dateigröße ist 25 MB. Der Benutzer kann Claude Fragen stellen, die im PDF-Dokument behandelt werden und Claude liefert die Antworten. Direkte Zitate können aus der PDF-Datei gefunden werden und Claude zeigt die Seitenzahl an, wo das Zitat vorkommt. Außerdem kann Claude PDF-Inhalt zusammenfassen. Copilot ist ebenfalls verfügbar, um schnellere Antworten auf prompts in einer menschlichen Art und Weise zu liefern. Bei umfangreichen Dateien werden die relevantesten Dateisegmente analysiert, um wichtige Antworten zu geben. Code kann erklärt und Dateien übersetzt werden. Claude und \gls{gpt4} gelten als intelligentere models, um große Dateien zu parsen \cite{perplexity}. \\

Adobe Firefly ist eine generative AI zur Erstellung von Bildern durch prompts. Im März 2023 wurde die Beta-Phase gestartet und seitdem haben Nutzer*innen mehr als 3 Milliarden Bilder generiert. Firefly ist in Photoshop, Illustrator und Adobe Express integriert, sowie als eigenständige Webanwendung aufgezogen worden. Bei Photoshop ist es als Generative Füllung und Generatives Erweitern eingebaut. Diese Funktionen ermöglichen dem Nutzer Bildinhalte per Text promt hinzuzufügen, zu entfernen, zu ersetzen oder zu erweitern, um Bilder umfassend zu ändern oder zu ergänzen. Im Bezug auf Illustrator wurden die Tools Generative Neufärbung, um Farbvarianten eines Designs zu erstellen, und Text to Vector Graphic, um aus einem prompt eine Vektorgrafik zu generieren, eingebaut. Adobe Express ergänzt Photoshop, Illustrator, Adobe Premiere Pro und Acrobat und ermöglicht den Import, die Bearbeitung und Synchronisierung von Assets zwischen den Applikationen für Echtzeitzusammenarbeit. Es wurde für schnelle Aufgaben, wie das Entfernen von Hintergründen, und die Erstellung von Inhalten für soziale Medien bzw. die Freigabe von Konzepten auf den Markt gebracht. In Adobe Express wird Firefly für die Text zu Bild, Texteffekte, Generative Füllung und Text to Template eingesetzt. Text to Template ermöglicht dem Benutzer durch einen prompt editierbare Templates zu generieren, um auf schnelle Art und Weise Social Posts, Poster, Flyer und digitale Karten zu erstellen. Die generierten Resultate von Text zu Bild und Texteffekte lassen sich in Adobe Express direkt als PDF-Datei speichern. Firefly unterstützt prompts in 100 Sprachen weltweit und die Webanwendung ist in 20 Sprachen verfügbar. In der Webanwendung ist kürzlich das Adobe Firefly Image 2 Model in der Beta-Version nebst Model 1 für mehr Gestaltungsmöglichkeiten und verbesserte Bildberechnung bzw. Bildqualität auf den Markt gebracht worden. Bei Text zu Bild wurde Generative Match implementiert, was einen einen Stil von mehreren vorausgewählten Bildern auf ein neues generiertes Bild anwendet. Der Bildstil kann mit integrierten Stileffekten kombiniert werden \cite{adobe-firefly}.     


\input{content/sectionFreieProgr}
\input{content/sectionKostenProgr}
\input{content/sectionPDFzuWord}
\input{content/sectionPDFzuLatex}
\input{content/sectionBranchen}
\input{content/sectionDruckDesign}



